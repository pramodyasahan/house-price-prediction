{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1c7c0f-ec85-44a8-9634-6ab73b348bce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/__init__.py:250\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[0;34m(key, accept_slice)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdtype_to_str\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'numpy.str_'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 95\u001b[0m\n\u001b[1;32m     88\u001b[0m preprocessor_selected \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[1;32m     89\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     90\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, numerical_transformer_selected, selected_numerical),\n\u001b[1;32m     91\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_transformer_selected, categorical_cols_selected)\n\u001b[1;32m     92\u001b[0m     ])\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Fit and transform the training data with selected features\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor_selected\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m X_test_selected \u001b[38;5;241m=\u001b[39m preprocessor_selected\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Now, you can proceed to fit your regression model using X_train_selected and y_train\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:740\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 740\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:448\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    446\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    447\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 448\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/__init__.py:405\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature column indices for input data X and key.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03mFor accepted values of `key`, see the docstring of\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m:func:`_safe_indexing_column`.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m n_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 405\u001b[0m key_dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_determine_key_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# we get an empty list\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/__init__.py:270\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[0;34m(key, accept_slice)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    269\u001b[0m     unique_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(key)\n\u001b[0;32m--> 270\u001b[0m     key_type \u001b[38;5;241m=\u001b[39m {_determine_key_type(elt) \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m unique_key}\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key_type:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/__init__.py:270\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    269\u001b[0m     unique_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(key)\n\u001b[0;32m--> 270\u001b[0m     key_type \u001b[38;5;241m=\u001b[39m {\u001b[43m_determine_key_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m unique_key}\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key_type:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev-ml/lib/python3.10/site-packages/sklearn/utils/__init__.py:252\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[0;34m(key, accept_slice)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dtype_to_str[\u001b[38;5;28mtype\u001b[39m(key)]\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accept_slice:\n",
      "\u001b[0;31mValueError\u001b[0m: No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Load your training and testing data\n",
    "training_dataset = pd.read_csv('train.csv')\n",
    "testing_dataset = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = training_dataset.drop('SalePrice', axis=1)\n",
    "X_train = X_train.drop('Id', axis=1)\n",
    "y_train = training_dataset['SalePrice']\n",
    "\n",
    "X_test = testing_dataset.drop('Id', axis=1)\n",
    "\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Combine the training and testing datasets for one-hot encoding\n",
    "combined_data = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "# Define transformers for numerical and categorical columns\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the combined data\n",
    "combined_data_transformed = preprocessor.fit_transform(combined_data)\n",
    "\n",
    "# Split the transformed data back into training and testing datasets\n",
    "X_train_transformed = combined_data_transformed[:len(X_train)]\n",
    "X_test_transformed = combined_data_transformed[len(X_train):]\n",
    "\n",
    "# Fit your model, let's assume RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Feature selection using RFE\n",
    "rfe = RFE(estimator=model, n_features_to_select=50)\n",
    "rfe = rfe.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the mask of selected features\n",
    "selected_mask = rfe.support_\n",
    "\n",
    "# Get the feature names for the categorical columns\n",
    "categorical_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the numerical and categorical feature names\n",
    "all_feature_names = np.array(numerical_cols.tolist() + categorical_feature_names.tolist())\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = all_feature_names[selected_mask]\n",
    "\n",
    "# Separate selected numerical and categorical features\n",
    "selected_numerical = [feature for feature in selected_features if feature in numerical_cols]\n",
    "selected_categorical = [feature for feature in selected_features if feature not in numerical_cols]\n",
    "\n",
    "# Create transformers for selected numerical and categorical features\n",
    "numerical_transformer_selected = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_selected = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Use 'most_frequent' for categorical\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a list of columns that need one-hot encoding (categorical columns)\n",
    "categorical_cols_selected = selected_categorical\n",
    "\n",
    "# Create a ColumnTransformer for selected features\n",
    "preprocessor_selected = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_selected, selected_numerical),\n",
    "        ('cat', categorical_transformer_selected, categorical_cols_selected)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the training data with selected features\n",
    "X_train_selected = preprocessor_selected.fit_transform(X_train)\n",
    "X_test_selected = preprocessor_selected.transform(X_test)\n",
    "\n",
    "# Now, you can proceed to fit your regression model using X_train_selected and y_train\n",
    "model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61ed47-c808-409c-8d58-3f15425b1fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
